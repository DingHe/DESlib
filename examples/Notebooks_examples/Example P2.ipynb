{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using the P2 problem\n",
    "\n",
    "This example requires the installation of the synthethic_datasets library in order to generate and plot the P2 problem. The library can be installed using pip: pip install git+https://github.com/Menelau/synthetic_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T23:56:26.118835Z",
     "start_time": "2018-07-01T23:56:26.109852Z"
    }
   },
   "outputs": [],
   "source": [
    "from deslib.dcs.ola import OLA\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from deslib.des.des_p import DESP\n",
    "from deslib.dcs.rank import Rank\n",
    "from syndata.synthetic_datasets import generate_p2\n",
    "from syndata.plot_tools import plot_classifier_decision, plot_dataset, plot_decision_P2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T23:53:39.589807Z",
     "start_time": "2018-07-01T23:53:39.482480Z"
    },
    "collapsed": true
   },
   "source": [
    "# Generating and plotting the P2 Dataset\n",
    "\n",
    "The P2 is a two-class problem, presented by Valentini, in which each class is defined in multiple decision regions delimited by polynomial and trigonometric functions. Here, $E4$ was modified such that the area of each class is approximately equal (Henniges, 2005).\n",
    "It is impossible to solve this problem using a single linear classifier, and the performance of the best possible linear classifier is around 50\\%. Code to generate and plot the P2 problem is available on the synthethic_datasets python library: https://github.com/Menelau/synthetic_datasets\n",
    "\n",
    "\n",
    "\\begin{eqnarray} \n",
    "\\label{eq:problem1}\n",
    "E1(x) = sin(x) + 5 \\\\\n",
    "\\label{eq:problem2}\n",
    "E2(x) = (x - 2)^{2} + 1 \\\\\n",
    "\\label{eq:problem3}\n",
    "E3(x) = -0.1 \\cdot x^{2} + 0.6sin(4x) + 8 \\\\\n",
    "\\label{eq:problem4}\n",
    "E4(x) = \\frac{(x - 10)^{2}}{2} + 7.902 \n",
    "\\end{eqnarray} \n",
    "\n",
    "[1] G. Valentini, An experimental bias-variance analysis of svm ensembles based on resampling techniques, IEEE Transactions on Systems, Man, and Cybernetics, Part B 35 (2005) 1252–1271.\n",
    "\n",
    "[2] P. Henniges, E. Granger, R. Sabourin, Factors of overtraining with fuzzy artmap neural networks, International Joint Conference on Neural Networks (2005) 1075–1080.\n",
    "\n",
    "The code below generates and plots the distribution of the P2 Dataset with the correct decision border:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T00:25:50.567054Z",
     "start_time": "2018-07-02T00:25:49.983131Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = generate_p2([1000, 1000])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "plot_dataset(X_train, y_train, ax=axs[0], title='Training set')\n",
    "plot_dataset(X_test, y_test, ax=axs[1], title='Test set')\n",
    "plot_decision_P2(ax=axs[0])\n",
    "plot_decision_P2(ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T23:53:41.063598Z",
     "start_time": "2018-07-01T23:53:41.013690Z"
    }
   },
   "source": [
    "# Baseline using standar classification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T00:25:53.909249Z",
     "start_time": "2018-07-02T00:25:52.535310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting classifiers\n",
    "svm_classifier = SVC().fit(X_train, y_train)\n",
    "mlp_classifier = MLPClassifier(max_iter=1000).fit(X_train, y_train)\n",
    "forest_classifier = RandomForestClassifier().fit(X_train, y_train)\n",
    "boosting_classifier = AdaBoostClassifier().fit(X_train, y_train)\n",
    "\n",
    "# evaluating classifiers\n",
    "print('SVM score = {}' .format(svm_classifier.score(X_test, y_test)))\n",
    "print('MLP score = {}' .format(mlp_classifier.score(X_test, y_test)))\n",
    "print('RF score = {}' .format(forest_classifier.score(X_test, y_test)))\n",
    "print('Boosting score = {}' .format(boosting_classifier.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the decison of the baseline methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T00:26:01.154117Z",
     "start_time": "2018-07-02T00:25:59.641436Z"
    }
   },
   "outputs": [],
   "source": [
    "fig2, sub = plt.subplots(2, 2, figsize=(15,10))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "titles = ['SVM decision', 'MLP decision', 'RF decision', 'Boosting decision']\n",
    "classifiers = [svm_classifier, mlp_classifier, forest_classifier, boosting_classifier]\n",
    "for clf, ax, title in zip(classifiers, sub.flatten(), titles):\n",
    "    plot_classifier_decision(ax, clf, X_test)\n",
    "    plot_dataset(X_test, y_test, ax=ax)\n",
    "    ax.set_xlim(np.min(X[:, 0]), np.max(X[:, 0]))\n",
    "    ax.set_ylim(np.min(X[:, 1]), np.max(X[:, 1]))\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a pool of 5 Perceptron classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_classifiers = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), n_estimators=5).fit(X_train, y_train)\n",
    "ax = plot_dataset(X_train, y_train, title='Five Decision Stumps set')\n",
    "for clf in pool_classifiers:\n",
    "    plot_classifier_decision(ax, clf, X_train)\n",
    "    ax.set_xlim((0,1))\n",
    "    ax.set_ylim((0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Dynamic Selection techniques.\n",
    "\n",
    "In this example we consider a pool composed of five linear perceptron classifiers. The Bagging technique is used to generate a diverse pool of classifiers.\n",
    "\n",
    "In this example we evaluate the performance of two DES: KNORA-Eliminate and DES-Performance and two DCS: Overal local accuracy and modified rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T00:26:05.019827Z",
     "start_time": "2018-07-02T00:26:04.306933Z"
    }
   },
   "outputs": [],
   "source": [
    "knora_e = KNORAE(pool_classifiers).fit(X_train, y_train)\n",
    "desp = DESP(pool_classifiers).fit(X_train, y_train)\n",
    "ola = OLA(pool_classifiers).fit(X_train, y_train)\n",
    "rank = Rank(pool_classifiers).fit(X_train, y_train)\n",
    "\n",
    "print('KNORAE score = {}' .format(knora_e.score(X_test, y_test)))\n",
    "print('DESP score = {}' .format(desp.score(X_test, y_test)))\n",
    "print('OLA score = {}' .format(ola.score(X_test, y_test)))\n",
    "print('Rank score = {}' .format(rank.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Decision Border of the DS methods. \n",
    "\n",
    "Even using only linear classifiers (with sometimes less than 50% accuracy) the DS techniques are able to have a good estimation of the complex decision border."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T00:26:16.406052Z",
     "start_time": "2018-07-02T00:26:09.156568Z"
    }
   },
   "outputs": [],
   "source": [
    "fig2, sub = plt.subplots(2, 2, figsize=(15,10))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "titles = ['KNORA-Eliminate', 'DES-P', 'Overal Local Accuracy (OLA)', 'Modified Rank']\n",
    "classifiers = [knora_e, desp, ola, rank]\n",
    "for clf, ax, title in zip(classifiers, sub.flatten(), titles):\n",
    "    plot_classifier_decision(ax, clf, X_train)\n",
    "    plot_dataset(X_test, y_test, ax=ax)\n",
    "    ax.set_xlim(np.min(X[:, 0]), np.max(X[:, 0]))\n",
    "    ax.set_ylim(np.min(X[:, 1]), np.max(X[:, 1]))\n",
    "    ax.set_title(title)\n",
    "plt.savefig('fig decision.png', dpi=450, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
