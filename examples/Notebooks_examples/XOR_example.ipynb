{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic selection on non-linear problems (XOR example)\n",
    "\n",
    "This example shows that DS can deal with non-linear problem (XOR) using a combination of a few linear base classifiers. \n",
    "\n",
    "- 14 dynamic selection methods (7 DES and 7 DCS) are evaluated with a pool composed of either Perceptrons or Decision stumps as base classifiers.\n",
    "\n",
    "- This example also compares the performance of Bagging and Boosting (AdaBoost) techniques, showing that they fail to properly solve this problem using only linear classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T01:10:00.058307Z",
     "start_time": "2018-07-02T01:09:53.131214Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# DCS techniques\n",
    "from deslib.dcs.ola import OLA\n",
    "from deslib.dcs.mcb import MCB\n",
    "from deslib.dcs.rank import Rank\n",
    "from deslib.dcs.a_posteriori import APosteriori\n",
    "from deslib.dcs.a_priori import APriori\n",
    "from deslib.dcs.lca import LCA\n",
    "from deslib.dcs.mla import MLA\n",
    "\n",
    "# DES techniques\n",
    "from deslib.des.des_p import DESP\n",
    "from deslib.des.des_clustering import DESClustering\n",
    "from deslib.des.des_knn import DESKNN\n",
    "from deslib.des.meta_des import METADES\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from deslib.des.knora_u import KNORAU\n",
    "from deslib.des.knop import KNOP\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the XOR problem with 1000 examples and plot its distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T20:41:57.480754Z",
     "start_time": "2018-05-26T20:41:57.458238Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_xor(n_samples):\n",
    "    X = np.random.uniform(low=-1, high=2, size=(n_samples, 2))\n",
    "    y = np.zeros(1000)\n",
    "\n",
    "    for idx, point in enumerate(X):\n",
    "        if point[0] < 0.5:\n",
    "                if point[1] < 0.5:\n",
    "                    y[idx] = 0\n",
    "                else:\n",
    "                    y[idx] = 1\n",
    "        else:\n",
    "            if point[1] < 0.5:\n",
    "                y[idx] = 1\n",
    "            else:\n",
    "                y[idx] = 0\n",
    "            \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T20:41:57.546301Z",
     "start_time": "2018-05-26T20:41:57.493263Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a504b1e6add7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_DSEL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_DSEL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0maxdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0maxdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0maxdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxhline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = create_xor(1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "X_DSEL, X_test, y_DSEL, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
    "axdata = plot_dataset(X, y)\n",
    "axdata.axvline(x=0.5, color='k')\n",
    "axdata.axhline(y=0.5, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T02:00:10.462996Z",
     "start_time": "2018-05-23T02:00:10.241850Z"
    }
   },
   "source": [
    "# Train the pool of classifiers\n",
    "\n",
    "Generating a pool of composed of 100 Perceptrons (pool_perceptrons) and another pool composed of 100 Decision stumps (pool_stumps) using the Bagging technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T01:09:47.680371Z",
     "start_time": "2018-07-02T01:09:47.560094Z"
    }
   },
   "outputs": [],
   "source": [
    "pool_perceptron = BaggingClassifier(Perceptron(max_iter=5), n_estimators=100).fit(X_train, y_train)\n",
    "pool_stumps = BaggingClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate pool for probabilities estimates\n",
    "\n",
    "This step is required when using Perceptron as base model since by default it does not estimate probabilities. The calibration is conducted using the validation dataset (X_DSEL), using the CalibratedClassifierCV class. In this example, we use the 'prefit' to indicate the method to calibrate the classifiers that were already trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T20:42:00.957303Z",
     "start_time": "2018-05-26T20:42:00.222780Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "pool_perceptron_calibrated = []\n",
    "pool_stump_calibrated = []\n",
    "for clf in pool_perceptron:\n",
    "    calibrated_clf = CalibratedClassifierCV(clf, cv='prefit')\n",
    "    calibrated_clf.fit(X_DSEL, y_DSEL)\n",
    "    pool_perceptron_calibrated.append(calibrated_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the DS techniques\n",
    "\n",
    "Initialize all DS techniques. Since all DS methods have the same method signature (fit, predict, predict_proba, score), we can easily create a list containing all of them to evaluate the performance later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T20:42:01.001842Z",
     "start_time": "2018-05-26T20:42:00.965815Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_ds(pool_classifiers, X, y, k=7):\n",
    "    # Initialize the DS techniques\n",
    "    knorau = KNORAU(pool_classifiers, k=k)\n",
    "    kne = KNORAE(pool_classifiers, k=k)\n",
    "    desknn = DESKNN(pool_classifiers, k=k)\n",
    "    ola = OLA(pool_classifiers, k=k)\n",
    "    lca = LCA(pool_classifiers, k=k)\n",
    "    mla = MLA(pool_classifiers, k=k)\n",
    "    mcb = MCB(pool_classifiers, k=k)\n",
    "    desp = DESP(pool_classifiers, k=k)\n",
    "    rank = Rank(pool_classifiers, k=k)    \n",
    "    apri = APriori(pool_classifiers, k=k)\n",
    "    apos = APosteriori(pool_classifiers, k=k)\n",
    "    des_clustering = DESClustering(pool_classifiers)\n",
    "    metades = METADES(pool_classifiers, k=k)\n",
    "    \n",
    "    list_ds = [knorau, kne, ola, lca, mcb, desp, rank, apri, apos, des_clustering, metades, mla, desknn]\n",
    "\n",
    "    # fit the ds techniques\n",
    "    for ds in list_ds:\n",
    "        ds.fit(X, y)\n",
    "    return list_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Phase\n",
    "\n",
    "### Get the classification accuracy of the DS methods as well as the Bagging technique (using the same pool of classifiers). \n",
    "\n",
    "This example the DS techniques uses the dynamic selection set (X_DSEL) to perform the dynamic selection stages. This set was not used to fit the base classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T20:42:16.638716Z",
     "start_time": "2018-05-26T20:42:01.015351Z"
    }
   },
   "outputs": [],
   "source": [
    "list_ds_stumps = initialize_ds(pool_stumps, X_DSEL, y_DSEL)\n",
    "for ds in list_ds_stumps:\n",
    "    print('Accuracy '+ ds.name + ': ' + str(ds.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T01:14:07.237572Z",
     "start_time": "2018-07-02T01:14:07.234076Z"
    }
   },
   "source": [
    "### Get the classification accuracy of the DS methods as well as the Bagging technique (using the same pool of classifiers). \n",
    "\n",
    "This example merge the training data with the validation, to create a DSEL having more example for the competence estimation.\n",
    "Using the training data for dynamic selection can be benefitial when dealing with small sample size datasets. However, in this case we need to have a pool composed of weak classifier so that the base classifiers are not able to memmorize the training data (overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T20:42:16.640718Z",
     "start_time": "2018-05-26T20:41:48.233Z"
    }
   },
   "outputs": [],
   "source": [
    "X_DSEL = np.vstack((X_DSEL, X_train))\n",
    "y_DSEL = np.hstack((y_DSEL, y_train))\n",
    "list_ds_stumps = initialize_ds(pool_stumps, X_DSEL, y_DSEL, k=10)\n",
    "for ds in list_ds_stumps:\n",
    "    print('Accuracy '+ ds.name + ': ' + str(ds.score(X_test, y_test)))\n",
    "print('Accuracy Bagging: '+str(pool_stumps.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the decison border of the DS methods\n",
    "\n",
    "The plotting is made using the functions from the synthetic_dataset library which provides methods to plot data and the decision of any classifier. The library is available on GitHub: https://github.com/Menelau/synthetic_datasets. \n",
    "\n",
    "The library can be installed using the following command:\n",
    "\n",
    "pip install git+https://github.com/Menelau/synthetic_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syndata.plot_tools import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T20:42:16.648223Z",
     "start_time": "2018-05-26T20:41:48.245Z"
    }
   },
   "outputs": [],
   "source": [
    "for ds in list_ds_stumps:\n",
    "    ax = plot_dataset(X, y)\n",
    "    plot_classifier_decision(ax, ds, X_test)\n",
    "    ax.set_xlim((np.min(X_test[:, 0])-0.1, np.max(X_test[:, 0]+0.1)))\n",
    "    ax.set_ylim((np.min(X_test[:, 1])-0.1, np.max(X_test[:, 1]+0.1)))\n",
    "    ax.set_title(ds.name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
